{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import traceback\n",
    "from os.path import exists\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# For playoff games, the 2nd digit of the specific number gives the round of the playoffs,\n",
    "# the 3rd digit specifies the matchup, and the 4th digit specifies the game (out of 7).\n",
    "game_type_map = {\"regular_season\": \"02\",\n",
    "                 \"playoffs\": \"03\"}\n",
    "year_list = [2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "\n",
    "class Directory:\n",
    "    DATA_DIR = \"../data/\" # Modify the path accordingly\n",
    "    ADV_VIZ_PKL_FILE = DATA_DIR + 'major_dict_1px.p'\n",
    "    ALL_SEASON_DATA_PKL_FILE = DATA_DIR + 'all_season.pkl'\n",
    "\n",
    "\n",
    "class APIList():\n",
    "    GET_ALL_MATCHES_FOR_A_GIVEN_SEASON = \"https://statsapi.web.nhl.com/api/v1/schedule?season=\"\n",
    "    GET_ALL_DATA_FOR_A_GIVEN_MATCH = \"https://statsapi.web.nhl.com/api/v1/game/{}/feed/live/\"\n",
    "\n",
    "\n",
    "class CustomRegex():\n",
    "    REGULAR_GAME_ID = r\"\\d{0,4}02\\d{0,4}\"  # 02 for regular season\n",
    "    PLAYOFFS_ID = r\"\\d{0,4}03\\d{0,4}\"  # 03 for playoffs\n",
    "\n",
    "\n",
    "TYPES_OF_SHOTS = [\"Goal\", \"Shot\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_of_matches_team_map(season_year):\n",
    "    \"\"\"\n",
    "    This function will fetch no of matches a team has played season wise.\n",
    "    Args:\n",
    "        season_year: season for which we need to find it out no of matches a team has played.\n",
    "    Returns: None; creates a pickle file\n",
    "\n",
    "    \"\"\"\n",
    "    response = requests.get(APIList.GET_ALL_MATCHES_FOR_A_GIVEN_SEASON + str(season_year) + str(season_year + 1))\n",
    "    list_of_all_matches = response.json()[\"dates\"]\n",
    "    game_id = []\n",
    "    home_team = []\n",
    "    away_team = []\n",
    "    for i in list_of_all_matches:\n",
    "        for j in i[\"games\"]:\n",
    "            game_id.append(j[\"gamePk\"])\n",
    "            home_team.append(j[\"teams\"][\"home\"][\"team\"][\"name\"])\n",
    "            away_team.append(j[\"teams\"][\"away\"][\"team\"][\"name\"])\n",
    "    df = pd.DataFrame({'game_id': game_id, 'home_team': home_team, 'away_team': away_team})\n",
    "    with open(Directory.DATA_DIR + str(season_year) + os.path.sep + 'no_of_matches_' + str(season_year) + '_.p',\n",
    "              'wb') as fp:\n",
    "        pickle.dump(df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def get_url(game_id: str):\n",
    "    \"\"\"\n",
    "    This funtions formats the url for a given game_id\n",
    "    @param game_id: input game id\n",
    "    @return: API in order to get the metadata for the given game id\n",
    "    \"\"\"\n",
    "    return APIList.GET_ALL_DATA_FOR_A_GIVEN_MATCH.format(game_id)\n",
    "\n",
    "\n",
    "def get_data_by_gameid(game_id: str):\n",
    "    \"\"\"\n",
    "    This function takes an input formatted game id and returns the data of that partical game\n",
    "    @param game_id:Game id in the form of \"2017020007\"\n",
    "    @return: Metadata for that particular game id\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = requests.get(get_url(game_id=game_id))\n",
    "        return data.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(traceback.print_exc())\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_all_relevant_game_ids_by_season(season_year: int):\n",
    "    \"\"\"\n",
    "    This functions fetches all the game ids having game type Regular Season and Playoffs\n",
    "    @param season_year: Season Year\n",
    "    @return: two list of game ids, one for regular and another for playoffs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(APIList.GET_ALL_MATCHES_FOR_A_GIVEN_SEASON + str(season_year) + str(season_year + 1))\n",
    "        list_of_all_matches = response.json()[\"dates\"]\n",
    "        reg_season_gameid_list = []\n",
    "        playoffs_gameid_list = []\n",
    "        for i in list_of_all_matches:\n",
    "            for j in i[\"games\"]:\n",
    "                if re.match(CustomRegex.REGULAR_GAME_ID, str(j[\"gamePk\"])):\n",
    "                    reg_season_gameid_list.append(j[\"gamePk\"])\n",
    "                elif re.match(CustomRegex.PLAYOFFS_ID, str(j[\"gamePk\"])):\n",
    "                    playoffs_gameid_list.append(j[\"gamePk\"])\n",
    "                else:\n",
    "                    pass\n",
    "        reg_season_gameid_list.sort()\n",
    "        playoffs_gameid_list.sort()\n",
    "        return reg_season_gameid_list, playoffs_gameid_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(traceback.print_exc())\n",
    "        pass\n",
    "\n",
    "\n",
    "def save_data_to_json(year, game_type, data, save_path):\n",
    "    \"\"\"\n",
    "    A function which will help the extracted data from the NHL API locally into a json file\n",
    "    @param year: Year / Season which we want to extract the data\n",
    "    @param game_type: Type of game, regular season or playoffs\n",
    "    @param data: fetched data\n",
    "    @param save_path: json path\n",
    "    @return: None\n",
    "    \"\"\"\n",
    "    path = Directory.DATA_DIR + save_path + os.path.sep + str(year) + \"_\" + game_type + \".json\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_data_by_season(year: int, out_path: str):\n",
    "    \"\"\"\n",
    "    This function will fetch both the games which are regular seasons and playoffs for the entire season\n",
    "    @param year: season year\n",
    "    @param out_path: directory where the file will save\n",
    "    @return:None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 2015 < year < 2021:\n",
    "            if exists(Directory.DATA_DIR + out_path):\n",
    "                print(\"Data exists locally, fetching the data from your system !!\")\n",
    "                regular_season_file_path = Directory.DATA_DIR + out_path + os.path.sep + str(year) \\\n",
    "                                           + \"_regular_season.json\"\n",
    "                playoffs_file_path = Directory.DATA_DIR + out_path + os.path.sep + str(year) + \"_playoffs.json\"\n",
    "                with open(regular_season_file_path, \"r\") as f:\n",
    "                    reg_season_game_data_list = json.load(f)\n",
    "\n",
    "                with open(playoffs_file_path, \"r\") as f:\n",
    "                    playoffs_game_data_list = json.load(f)\n",
    "\n",
    "                return reg_season_game_data_list, playoffs_game_data_list\n",
    "            else:\n",
    "                os.mkdir(Directory.DATA_DIR + out_path)\n",
    "                get_no_of_matches_team_map(season_year=year)\n",
    "                reg_season_game_data_dict = {}\n",
    "                playoffs_game_data_dict = {}\n",
    "                reg_season_gameid_list, playoffs_gameid_list = get_all_relevant_game_ids_by_season(season_year=year)\n",
    "                for reg_season_game_id in tqdm(reg_season_gameid_list):\n",
    "                    match_data = get_data_by_gameid(game_id=reg_season_game_id)\n",
    "                    reg_season_game_data_dict[reg_season_game_id] = match_data\n",
    "                for playoff_game_id in tqdm(playoffs_gameid_list):\n",
    "                    match_data = get_data_by_gameid(game_id=playoff_game_id)\n",
    "                    playoffs_game_data_dict[playoff_game_id] = match_data\n",
    "\n",
    "                save_data_to_json(year=year, game_type=\"regular_season\", data=reg_season_game_data_dict,\n",
    "                                  save_path=out_path)\n",
    "                save_data_to_json(year=year, game_type=\"playoffs\", data=playoffs_game_data_dict,\n",
    "                                  save_path=out_path)\n",
    "\n",
    "                return reg_season_game_data_dict, playoffs_game_data_dict, \"Success\"\n",
    "        else:\n",
    "            return {}, {}, \"Invalid Year\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(traceback.print_exc())\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2016, 2017, 2018, 2019, 2020]\n",
    "    for y in year:\n",
    "        results = get_all_data_by_season(year=y, out_path=str(y))\n",
    "        # save files into the respective directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
