{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f665deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from comet_ml import Experiment\n",
    "import os\n",
    "import pickle\n",
    "import configparser\n",
    "np.random.seed(42)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1dcb899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/amandalmia/baseline-models/1691d05e9a2a486492e1ca3a60234d1c\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=c439ad63b0ab4d84a50b4794a2c4dfe0&experimentKey=1691d05e9a2a486492e1ca3a60234d1c',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=c439ad63b0ab4d84a50b4794a2c4dfe0&experimentKey=1691d05e9a2a486492e1ca3a60234d1c',\n",
       " 'assetId': 'c439ad63b0ab4d84a50b4794a2c4dfe0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../configfile.ini')\n",
    "type_env = \"comet_ml_prod\" #comet_ml_prod\n",
    "COMET_API_KEY = config[type_env]['api_key']\n",
    "COMET_PROJECT_NAME = config[type_env]['project_name_baseline']\n",
    "COMET_WORKSPACE = config[type_env]['workspace']\n",
    "\n",
    "comet_exp_obj = Experiment(api_key=COMET_API_KEY,\n",
    "                           project_name=COMET_PROJECT_NAME,\n",
    "                           workspace=COMET_WORKSPACE,\n",
    "                           log_code=True\n",
    "                          )\n",
    "comet_exp_obj.set_name(name=\"Baseline Models\")\n",
    "comet_exp_obj.log_notebook(\"9_baseline_models_all.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5bec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_datafile():\n",
    "    data = pd.read_pickle(\"../data/trainvaldata/train_set.pkl\")\n",
    "    data = data.dropna()\n",
    "    print(data.shape)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data, data[\"is_goal\"], test_size=0.2, stratify=data[\"is_goal\"], \n",
    "                                                          random_state=42)\n",
    "    train_df = x_train.copy()\n",
    "    train_df[\"is_goal\"] = y_train\n",
    "    train_df[\"train-val\"] = 0\n",
    "\n",
    "    val_df = x_val.copy()\n",
    "    val_df[\"is_goal\"] = y_val\n",
    "    val_df[\"train-val\"] = 1\n",
    "\n",
    "    df = train_df.append(val_df, ignore_index=True)\n",
    "    df.to_pickle(\"../data/trainvaldata/train_val_df.pkl\") # Raphael use this and preprocess and share the x_train, y_train ....\n",
    "\n",
    "# create_train_val_datafile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a8d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: pandas_profiling is required to log profile; ignoring\n",
      "COMET WARNING: pandas_profiling is required to log profile; ignoring\n",
      "COMET WARNING: pandas_profiling is required to log profile; ignoring\n",
      "COMET WARNING: pandas_profiling is required to log profile; ignoring\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_pickle(\"../data/trainvaldata/x_train.pkl\")\n",
    "x_val = pd.read_pickle(\"../data/trainvaldata/x_val.pkl\")\n",
    "y_train = pd.read_pickle(\"../data/trainvaldata/y_train.pkl\")\n",
    "y_val = pd.read_pickle(\"../data/trainvaldata/y_val.pkl\")\n",
    "\n",
    "comet_exp_obj.log_dataframe_profile(x_train, \"x_train\")\n",
    "comet_exp_obj.log_dataframe_profile(y_train, \"y_train\")\n",
    "comet_exp_obj.log_dataframe_profile(x_val, \"x_val\")\n",
    "comet_exp_obj.log_dataframe_profile(y_val, \"y_val\")\n",
    "\n",
    "x_train_df_distance = x_train[['distance']]\n",
    "x_train_df_angle = x_train[['angle']]\n",
    "x_train_df_distance_angle = x_train[['distance','angle']]\n",
    "y_train = y_train.values\n",
    "\n",
    "x_val_df_distance = x_val[['distance']]\n",
    "x_val_df_angle = x_val[['angle']]\n",
    "x_val_df_distance_angle = x_val[['distance','angle']]\n",
    "y_val = y_val.values\n",
    "\n",
    "\n",
    "data_train_dict = {\n",
    "    \"distance\" : (x_train_df_distance, y_train, 1),\n",
    "    \"angle\" : (x_train_df_angle, y_train, 1),\n",
    "    \"distance_angle\" : (x_train_df_distance_angle, y_train, 2),\n",
    "    \"random_base_line\" : ()\n",
    "}\n",
    "\n",
    "data_val_dict = {\n",
    "    \"distance\" : (x_val_df_distance, y_val, 1),\n",
    "    \"angle\" : (x_val_df_angle, y_val, 1),\n",
    "    \"distance_angle\" : (x_val_df_distance_angle, y_val, 2),\n",
    "    \"random_base_line\" : ()\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb62447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Matrix for BaseLine Model for features -  distance\n",
      "correctly predicted / total is  90.97315701955816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     57445\n",
      "           1       0.00      0.00      0.00      5700\n",
      "\n",
      "    accuracy                           0.91     63145\n",
      "   macro avg       0.45      0.50      0.48     63145\n",
      "weighted avg       0.83      0.91      0.87     63145\n",
      "\n",
      "[[57445     0]\n",
      " [ 5700     0]]\n",
      "Classification Matrix for BaseLine Model for features -  angle\n",
      "correctly predicted / total is  90.97315701955816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     57445\n",
      "           1       0.00      0.00      0.00      5700\n",
      "\n",
      "    accuracy                           0.91     63145\n",
      "   macro avg       0.45      0.50      0.48     63145\n",
      "weighted avg       0.83      0.91      0.87     63145\n",
      "\n",
      "[[57445     0]\n",
      " [ 5700     0]]\n",
      "Classification Matrix for BaseLine Model for features -  distance_angle\n",
      "correctly predicted / total is  90.97315701955816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     57445\n",
      "           1       0.00      0.00      0.00      5700\n",
      "\n",
      "    accuracy                           0.91     63145\n",
      "   macro avg       0.45      0.50      0.48     63145\n",
      "weighted avg       0.83      0.91      0.87     63145\n",
      "\n",
      "[[57445     0]\n",
      " [ 5700     0]]\n",
      "Classification Matrix for BaseLine Model for features -  random_base_line\n",
      "correctly predicted / total is  49.89627048855808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.64     57445\n",
      "           1       0.09      0.49      0.15      5700\n",
      "\n",
      "    accuracy                           0.50     63145\n",
      "   macro avg       0.50      0.50      0.40     63145\n",
      "weighted avg       0.83      0.50      0.60     63145\n",
      "\n",
      "[[28688 28757]\n",
      " [ 2881  2819]]\n"
     ]
    }
   ],
   "source": [
    "def build_log_reg_model(model, x_val, y_val, no_of_features, k):\n",
    "    if no_of_features == 1:\n",
    "        x_val = x_val.values.reshape(-1, 1)\n",
    "        \n",
    "    y_pred = model.predict(x_val)\n",
    "    accuracy = np.mean(y_val == y_pred) * 100\n",
    "    print(\"correctly predicted / total is \", accuracy)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    metrics = {k + \"_feature_accuracy\":accuracy}\n",
    "    classNames = np.unique(y_val)\n",
    "\n",
    "    comet_exp_obj.log_metrics(metrics)\n",
    "    comet_exp_obj.log_confusion_matrix(y_true=y_val, y_predicted=y_pred, title=\"Confusion Matrix for \" + k,\n",
    "                                      file_name=\"Confusion Matrix for \" + k)\n",
    "\n",
    "for k, v in data_train_dict.items():\n",
    "    print(\"Classification Matrix for BaseLine Model for features - \", k)\n",
    "    if k != \"random_base_line\":\n",
    "        x_train = v[0]\n",
    "        y_train = v[1]\n",
    "        x_val = data_val_dict[k][0]\n",
    "        y_val = data_val_dict[k][1]\n",
    "        no_of_features = v[2]\n",
    "        if no_of_features == 1:\n",
    "            x_train = x_train.values.reshape(-1, 1)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        build_log_reg_model(model, x_val, y_val, no_of_features, k)\n",
    "        \n",
    "        filename = '../model/' + k + \"_model.pkl\"\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        comet_exp_obj.log_model(k, file_or_folder=filename, overwrite=True, file_name=k)\n",
    "        \n",
    "    else:\n",
    "        y_pred = np.array([np.random.uniform(low=0.0, high=1.0) for i in range(y_val.shape[0])])\n",
    "        y_pred[y_pred > 0.5] = 1\n",
    "        y_pred[y_pred <= 0.5] = 0\n",
    "        y_pred = y_pred.astype(int)\n",
    "        \n",
    "        accuracy = np.mean(y_val == y_pred) * 100\n",
    "        metrics = {k + \"_feature_accuracy\":accuracy}\n",
    "        comet_exp_obj.log_metrics(metrics)\n",
    "        print(\"correctly predicted / total is \", accuracy)\n",
    "        print(classification_report(y_val, y_pred))\n",
    "        print(confusion_matrix(y_val, y_pred))\n",
    "        comet_exp_obj.log_confusion_matrix(y_true=y_val, y_predicted=y_pred, title=\"Confusion Matrix for \" + k,\n",
    "                                      file_name=\"Confusion Matrix for \" + k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969675c9",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Evaluate the accuracy (i.e. correctly predicted / total) of your model on the validation set. What do you notice? Look at the predictions and discuss your findings. What could be a potential issue? Include these discussions in your blog post.\n",
    "\n",
    "- Allthough the accuracy is showing up 90% of accuracy, but this number isn't right in my opion. As the major class is 0s, and the ratio of trainign data of shot being goal and not-goal is highly imbalance and is in the order of 1:10. \n",
    "- From the classificatinon report its clear that all the test data (validation data) has been predicted to 0s as the output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882566c1",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Receiver Operating Characteristic (ROC) curves and the AUC metric of the ROC curve. Include a random classifier baseline, i.e. each shot has a 50% chance of being a goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_auc_curve(comet_exp_obj, model, x_val, y_val, no_of_features):    \n",
    "    testy = y_val\n",
    "    ns_probs = [0 for _ in range(len(testy))]\n",
    "    \n",
    "    predicted_probablities = model.predict_proba(x_val)\n",
    "    goal_prob = predicted_probablities[:, 1] # taking only the goal probablities\n",
    "    # https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(testy, ns_probs)\n",
    "    lr_auc = round(roc_auc_score(testy, goal_prob), 8)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(testy, goal_prob)\n",
    "    \n",
    "    return ns_fpr, ns_tpr, lr_fpr, lr_tpr, ns_auc, lr_auc\n",
    "    \n",
    "    \n",
    "plt.figure()    \n",
    "table_values = []\n",
    "markers_list = [\",\", \",\", \",\", \",\", \"P\"]\n",
    "for index, (k, v) in enumerate(data_train_dict.items()):\n",
    "    lw=5-4*index/len(data_train_dict)\n",
    "    ls=['-','--','-.',':'][index%4]\n",
    "    print(\"AUC ROC Scores for BaseLine Model for features - \", k)\n",
    "    if k != \"random_base_line\":\n",
    "        x_train = v[0]\n",
    "        y_train = v[1]\n",
    "        x_val = data_val_dict[k][0]\n",
    "        y_val = data_val_dict[k][1]\n",
    "        no_of_features = v[2]\n",
    "        if no_of_features == 1:\n",
    "            x_train = x_train.values.reshape(-1, 1)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        ns_fpr, ns_tpr, lr_fpr, lr_tpr, ns_auc, lr_auc = create_roc_auc_curve(comet_exp_obj, model, \n",
    "                                                                              x_val, y_val, no_of_features)\n",
    "        table_values.append([ns_auc, lr_auc])\n",
    "        # plot the roc curve for the model\n",
    "        plt.plot(lr_fpr, lr_tpr, marker=markers_list[index], label=k, linewidth=lw, linestyle=ls)\n",
    "    else:\n",
    "        testy = y_val\n",
    "        ns_probs = [0 for _ in range(len(testy))]\n",
    "        y_pred = np.array([np.random.uniform(low=0.0, high=1.0) for i in range(y_val.shape[0])])\n",
    "        goal_prob = y_pred\n",
    "        \n",
    "        ns_auc = roc_auc_score(testy, ns_probs)\n",
    "        lr_auc = round(roc_auc_score(testy, goal_prob), 8)\n",
    "        # summarize scores\n",
    "        print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "        print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "        # calculate roc curves\n",
    "        ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "        lr_fpr, lr_tpr, _ = roc_curve(testy, goal_prob)\n",
    "        table_values.append([ns_auc, lr_auc])\n",
    "        plt.plot(lr_fpr, lr_tpr, marker=markers_list[index], label=k, linewidth=lw, linestyle=ls)\n",
    "    \n",
    "# create_roc_auc_curve(comet_exp_obj, model, x_val, y_val, no_of_features)\n",
    "col_labels=['No Skill: ROC AUC','Logistic: ROC AUC']\n",
    "row_labels=[*data_train_dict]\n",
    "table_vals=table_values\n",
    "the_table = plt.table(cellText=table_vals,\n",
    "                  colWidths = [0.15]*3,\n",
    "                  rowLabels=row_labels,\n",
    "                  colLabels=col_labels,\n",
    "                  loc='center right')\n",
    "plt.text(0.8,0.75,'Table ROC AUC',size=8)\n",
    "\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Base Line')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) curves and the AUC metric\")\n",
    "plt.legend()\n",
    "comet_exp_obj.log_figure(figure_name=\"Receiver Operating Characteristic (ROC) curves and the AUC metric\", \n",
    "                             figure=plt, overwrite=False, step=None)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe6a43",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "The goal rate (#goals / (#no_goals + #goals)) as a function of the shot probability model percentile, i.e. if a value is the 70th percentile, it is above 70% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_goal_shot_rate(plt1, model, x_val, y_val, k):\n",
    "    testy = y_val\n",
    "    ns_probs = [0 for _ in range(len(y_val))]\n",
    "    predicted_probablities = model.predict_proba(x_val)\n",
    "    goal_prob = predicted_probablities[:, 1] # taking only the goal probablities\n",
    "    \n",
    "    df = pd.DataFrame(y_val, columns=[\"is_goal\"])\n",
    "    df[\"probablity_of_goal\"] = goal_prob\n",
    "    df['percentile_of_goal'] = round(df[\"probablity_of_goal\"].rank(pct = True)*100)\n",
    "    goal_rate = round((df.groupby(by='percentile_of_goal').sum() / \n",
    "                       df.groupby(by='percentile_of_goal').count())*100)\n",
    "    goal_rate['percentile'] = goal_rate.index\n",
    "\n",
    "    plt1.plot(goal_rate[\"percentile\"], goal_rate[\"is_goal\"], label=k)\n",
    "\n",
    "\n",
    "fig, (plt1) = plt.subplots(1, 1)\n",
    "for index, (k, v) in enumerate(data_train_dict.items()):\n",
    "    print(\"Goal Shot Rate for BaseLine Model for features - \", k)\n",
    "    if k != \"random_base_line\":\n",
    "        x_train = v[0]\n",
    "        y_train = v[1]\n",
    "        x_val = data_val_dict[k][0]\n",
    "        y_val = data_val_dict[k][1]\n",
    "        no_of_features = v[2]\n",
    "        if no_of_features == 1:\n",
    "            x_train = x_train.values.reshape(-1, 1)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        plot_goal_shot_rate(plt1, model, x_val, y_val, k)\n",
    "        \n",
    "    else:\n",
    "        goal_prob = np.array([np.random.uniform(low=0.0, high=1.0) for i in range(x_val.shape[0])])\n",
    "        df = pd.DataFrame(y_val, columns=[\"is_goal\"])\n",
    "        df[\"probablity_of_goal\"] = goal_prob\n",
    "\n",
    "        df['percentile_of_goal'] = round(df[\"probablity_of_goal\"].rank(pct = True)*100)\n",
    "        goal_rate = round((df.groupby(by='percentile_of_goal').sum() / \n",
    "                           df.groupby(by='percentile_of_goal').count())*100)\n",
    "        goal_rate['percentile'] = goal_rate.index\n",
    "        plt1.plot(goal_rate[\"percentile\"], goal_rate[\"is_goal\"], label=k)\n",
    "\n",
    "plt1.set_ylim(0,100)\n",
    "plt1.xaxis.set_major_formatter('{x:1.0f}%')\n",
    "plt1.yaxis.set_major_formatter('{x:1.0f}%')\n",
    "plt1.invert_xaxis()\n",
    "plt1.set_xlabel('Shot probablity model percentile')\n",
    "plt1.set_ylabel('Goals / (No Goals + Goals)')\n",
    "plt.grid()\n",
    "plt.title(\"Goal Rate\")\n",
    "plt.legend()\n",
    "comet_exp_obj.log_figure(figure_name=\"Goal Rate\", figure=fig,\n",
    "                   overwrite=False, step=None)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_goal(plt1, comet_exp_obj, model, x_val, y_val, k, ls, lw):\n",
    "    testy = y_val\n",
    "    ns_probs = [0 for _ in range(len(y_val))]\n",
    "    \n",
    "    predicted_probablities = model.predict_proba(x_val)\n",
    "\n",
    "    goal_prob = predicted_probablities[:, 1] # taking only the goal probablities\n",
    "    \n",
    "    df = pd.DataFrame(y_val, columns=[\"is_goal\"])\n",
    "    df[\"probablity_of_goal\"] = goal_prob\n",
    "    \n",
    "    df['percentile_of_goal'] = round(df[\"probablity_of_goal\"].rank(pct = True)*100)\n",
    "    goal_rate = df.groupby(by='percentile_of_goal').sum()\n",
    "    goal_rate['percentile'] = goal_rate.index\n",
    "    \n",
    "    goal_rate['cum_sum'] = goal_rate.loc[::-1, 'is_goal'].cumsum()[::-1]\n",
    "    goal_rate['cum_perc'] = 100*goal_rate['cum_sum'] / goal_rate['is_goal'].sum()\n",
    "    \n",
    "    plt1.plot(goal_rate[\"percentile\"], goal_rate[\"cum_perc\"], label=k, linewidth=lw, linestyle=ls)\n",
    "\n",
    "graph, (plt1) = plt.subplots(1, 1)\n",
    "\n",
    "for index, (k, v) in enumerate(data_train_dict.items()):\n",
    "    print(\"Cumulative Goal for BaseLine Model for features - \", k)\n",
    "    lw=5-4*index/len(data_train_dict)\n",
    "    ls=['-','--','-.',':'][index%4]\n",
    "    if k != \"random_base_line\":\n",
    "        x_train = v[0]\n",
    "        y_train = v[1]\n",
    "        x_val = data_val_dict[k][0]\n",
    "        y_val = data_val_dict[k][1]\n",
    "        no_of_features = v[2]\n",
    "        if no_of_features == 1:\n",
    "            x_train = x_train.values.reshape(-1, 1)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        plot_cumulative_goal(plt1, comet_exp_obj, model, x_val, y_val, k, ls, lw)\n",
    "        \n",
    "    else:\n",
    "        ggoal_prob = np.array([np.random.uniform(low=0.0, high=1.0) for i in range(x_val.shape[0])])\n",
    "        df = pd.DataFrame(y_val, columns=[\"is_goal\"])\n",
    "        df[\"probablity_of_goal\"] = goal_prob\n",
    "\n",
    "        df['percentile_of_goal'] = round(df[\"probablity_of_goal\"].rank(pct = True)*100)\n",
    "        goal_rate = df.groupby(by='percentile_of_goal').sum()\n",
    "        goal_rate['percentile'] = goal_rate.index\n",
    "\n",
    "        goal_rate['cum_sum'] = goal_rate.loc[::-1, 'is_goal'].cumsum()[::-1]\n",
    "        goal_rate['cum_perc'] = 100*goal_rate['cum_sum'] / goal_rate['is_goal'].sum()\n",
    "        plt1.plot(goal_rate[\"percentile\"], goal_rate[\"cum_perc\"], label=k, linewidth=lw, linestyle=ls)\n",
    "\n",
    "plt1.set_ylim(0,100)\n",
    "plt1.invert_xaxis()\n",
    "plt1.set_xlabel('Shot probablity model percentile')\n",
    "plt1.set_ylabel('Proportion')\n",
    "plt.grid()\n",
    "plt.title(\"Cumulative % of goals\")\n",
    "plt.legend()\n",
    "comet_exp_obj.log_figure(figure_name=\"Cumulative % of goals\", figure=plt,\n",
    "                   overwrite=False, step=None)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ddd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extimator_plot(comet_exp_obj, model, x_val, y_val, k):\n",
    "    testy = y_val\n",
    "    ns_probs = [0 for _ in range(len(y_val))]\n",
    "    \n",
    "    predicted_probablities = model.predict_proba(x_val)\n",
    "    goal_prob = predicted_probablities[:, 1] # taking only the goal probablities\n",
    "    return CalibrationDisplay.from_predictions(y_val, goal_prob, ax=ax_calibration_curve,name=k)\n",
    "#     return CalibrationDisplay.from_estimator(model, x_val, y_val, ax=ax_calibration_curve)\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = GridSpec(4, 2)\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "\n",
    "for index, (k, v) in enumerate(data_train_dict.items()):\n",
    "    print(\"Estimator Plot for BaseLine Model for features - \", k)\n",
    "    if k != \"random_base_line\":\n",
    "        x_train = v[0]\n",
    "        y_train = v[1]\n",
    "        x_val = data_val_dict[k][0]\n",
    "        y_val = data_val_dict[k][1]\n",
    "        no_of_features = v[2]\n",
    "        if no_of_features == 1:\n",
    "            x_train = x_train.values.reshape(-1, 1)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        calibration_displays[k] = create_extimator_plot(comet_exp_obj, model, x_val, y_val, k)\n",
    "        \n",
    "    else:\n",
    "        goal_prob = np.array([np.random.uniform(low=0.0, high=1.0) for i in range(x_val.shape[0])])\n",
    "        calibration_displays[k] = CalibrationDisplay.from_predictions(y_val, goal_prob, ax=ax_calibration_curve, \n",
    "                                                                      name=k)\n",
    "\n",
    "        \n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "comet_exp_obj.log_figure(figure_name=\"Calibration Display\", figure=plt,\n",
    "                   overwrite=False, step=None)\n",
    "comet_exp_obj.end()\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07901f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
